# Liandrin : Time-travelling Conversational AI Assistant

This project is a real-time voice-based conversational AI assistant built with FastAPI, WebSockets, and modern AI services. It lets users speak with the assistant using their microphone, transcribes speech in real-time, generates AI-driven responses, and streams back natural-sounding audio responses.
Think of it as a two-way voice conversation with an AI, powered by:
AssemblyAI for real-time transcription (STT)
Google Gemini for large language model (LLM) responses
Murf for text-to-speech (TTS)
News API + SerpAPI (optional integrations for context/data retrieval)
The entire pipeline runs in real-time, handling audio streaming, AI response generation, and audio playback seamlessly.

## ğŸš€ Features

âœ… Web-based Interface â€“ Works directly in the browser with no installations required.</br>
âœ… API Key Management â€“ Securely set and store API keys from the UI.</br>
âœ… Real-Time Speech Recognition â€“ Streams audio to AssemblyAI for transcription.</br>
âœ… Conversational AI â€“ Sends transcribed text to a Gemini LLM for natural language responses.</br>
âœ… Text-to-Speech Streaming â€“ Uses Murf to generate realistic AI voice responses.</br>
âœ… WebSocket-based Streaming â€“ Full-duplex communication between client and server.</br>
âœ… Fallback Handling â€“ Provides pre-recorded fallback audio if APIs are unavailable.</br>
âœ… Chat History â€“ Keeps track of past messages for context-aware conversations.</br>

## ğŸ—ï¸ Architecture

Frontend (script.js + index.html)</br>
Captures microphone input via Web Audio API</br>
Streams PCM audio over WebSocket (/ws)</br>
Displays live transcriptions & AI responses</br>
Queues and plays back streamed audio chunks</br>
Backend (FastAPI - main.py)</br>

```/set_keys``` â†’ Save API keys to .env file

```/agent/chat``` â†’ STT â†’ LLM â†’ TTS pipeline for one-shot requests

```/ws``` â†’ Real-time bi-directional streaming (STT + LLM + TTS)

```/tts```& ```/voices``` â†’ Direct TTS endpoints

Uses AssemblyAI StreamingClient for live transcription

Runs LLM + TTS pipeline per user session

External Services

AssemblyAI â†’ Speech-to-Text (real-time streaming)

Google Gemini â†’ Conversational responses

Murf â†’ Voice generation (TTS)

News API + SerpAPI â†’ Optional retrieval augmentation

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ main.py                # FastAPI app (backend logic)
â”œâ”€â”€ services/              # STT, LLM, and TTS service wrappers
â”œâ”€â”€ schemas/               # Pydantic request/response schemas
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Frontend UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js          # Client-side logic
â”‚   â””â”€â”€ fallback.mp3       # Fallback audio
â”œâ”€â”€ uploads/               # Saved audio streams
â”œâ”€â”€ config.py              # Configuration (env vars loaded here)
â”œâ”€â”€ .env                   # API keys (autogenerated)
â””â”€â”€ README.md              # Documentation
```
## âš™ï¸ Setup & Installation</br>
1ï¸âƒ£ Clone the Repository</br>
```
git clone https://github.com/vignesh-naik-720/Liandrin.git
cd Liandrin
```
2ï¸âƒ£ Create Virtual Environment & Install Dependencies</br>
```
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

pip install -r requirements.txt
```
3ï¸âƒ£ Set Up Environment Variables

API keys can be set in two ways:

Option A (recommended) â†’ Enter keys in the frontend modal (stored in .env)

Option B â†’ Manually create .env file:
```
MURF_API_KEY=your_murf_key
ASSEMBLYAI_API_KEY=your_assemblyai_key
GEMINI_API_KEY=your_gemini_key
NEWS_API_KEY=your_news_key
SERP_API_KEY=your_serp_key
```
4ï¸âƒ£ Run the Server
```
uvicorn main:app --reload
```

Now visit ```http://127.0.0.1:8000```
 in your browser.

## ğŸ¤ Usage

Open the app in your browser.

Enter your API keys in the modal (one-time setup).

Click Record ğŸ™ï¸ and start speaking.

Watch your speech transcription appear in real-time.

The AI assistant will generate a response and speak back.

Continue the conversation naturally.

## Live Demo:
Link: https://liandrin.onrender.com/

## ğŸ›¡ï¸ Security Notes

API keys are saved in .env and never exposed to frontend after initial input.

WebSocket connection is session-specific (unique session_id per client).

Audio files are stored in /uploads but can be auto-cleaned in production.

For production:

Use HTTPS (wss://)

Rotate API keys regularly

Consider rate-limiting

## ğŸ› ï¸ Tech Stack

Backend: FastAPI + WebSockets

Frontend: Vanilla JS + Web Audio API

AI Services: AssemblyAI, Google Gemini, Murf, SerpAPI, News API

Infra: Uvicorn

## ğŸ“Œ Future Enhancements

âœ… Add user authentication</br>

âœ… Store chat history in database (SQLite/Postgres)</br>

âœ… Deploy with Docker + Render/Heroku</br>

âœ… Add support for multiple TTS providers (e.g., ElevenLabs)</br>

âœ… Add streaming avatars with lip-sync</br>
